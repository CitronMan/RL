由于模型无关的强化学习比较复杂，今天先介绍其中一部分——模型无关的策略评价。
模型无关的策略评价是，不知道马尔科夫决策过程转移概率和奖励函数的情况下，
计算一个策略的每一个状态价值。模型无关的策略评价主要有两种算法，一个是
蒙特卡罗算法，另一个叫时差学习算法。


蒙特卡罗算法能够有效地求解模型无关的策略评估，但也存在一些问题。有时我们
面临的强化学习问题是持续不断的。比如没有停止指令时，飞行器控制要求不停地根
据姿势风向等因素调整，持续保持平稳飞行。这时我们得不到一个完整状态-动作-奖
励系列，因此蒙特卡罗算法不适用。为了解决这个问题，人们提出了时差学习算法 (
Temperal Difference, TD)。时差学习算法利用马尔科夫性质，只利用了下一
步信息。时差学习算法让系统按照策略指引进行探索，在探索每一步都进行状态价值的更新，

